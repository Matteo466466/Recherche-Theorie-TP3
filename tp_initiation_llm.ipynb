{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matteo466466/Recherche-Theorie-TP3/blob/main/tp_initiation_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_ulIfX4hiN_"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vincentmartin/tp-initiation-llm-student-version/blob/main/TP_initiation_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUSbWzyYhiOC"
      },
      "source": [
        "# TP d'initiation aux LLM\n",
        "\n",
        "Dans ce TP, vous allez apprendre les bases de l'IA générative en manipulant et en contrôlant un LLM installé en local.\n",
        "\n",
        "En sortie de ce module, vous serez capable de :\n",
        "- Installer et importer les dépendances nécessaires\n",
        "- Interroger un LLM pour répondre à tout type de question, comme avec chatGPT\n",
        "- Analyser le fonctionnement d'un LLM\n",
        "- Utiliser un LLM pour résumer une conversation\n",
        "- Explorer les techniques de zero-shot, one-shot et few-shot inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRZ9Gc13hiOD"
      },
      "source": [
        "### Instruction à suivre pour exécution sur Google Colab\n",
        "\n",
        "Aller dans `Execution -> Modifier le type d'exécution` puis sélectionner `T4-GPU` pour exploiter les fonctionnalités GPU.\n",
        "\n",
        "![Colab GPU](resources/colab_gpu.png \"T4-GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aTqMFeAhiOD"
      },
      "source": [
        "## Installation des dépendances\n",
        "\n",
        "Installons les dépendances nécessaires :\n",
        "- **transformers** : la bibliothèque permettant de mettre en oeuvre les LLM exploitant le modèle transformers\n",
        "- **torch** : célèbre bibliothèque de deep learning, sous jacente à transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iAaTBnhWhiOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03387e5e-f4eb-403a-ffd9-b22259686bf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.12/dist-packages (from torchdata) (2.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchdata) (2.32.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchdata) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchdata) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchdata) (2025.11.12)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "%pip install -U datasets\n",
        "\n",
        "%pip install --upgrade pip\n",
        "%pip install --disable-pip-version-check \\\n",
        "    torch \\\n",
        "    torchdata\n",
        "\n",
        "%pip install \\\n",
        "    transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03yBWmgehiOE"
      },
      "source": [
        "Chargeons les dépendances.\n",
        "\n",
        "**Remarque : Si l'exécution ressort en erreur ; tenter de recharger les dépendances.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "tsuWpbE_hiOF"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import GenerationConfig\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "itThLBGniiab"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c55qn6QZhiOF"
      },
      "source": [
        "## Chargement du LLM\n",
        "\n",
        "Pour interagir avec un LLM, nous allons d'abord devoir le télécharger. Pour cet exemple, nous choissons un modèle simple et \"léger\" : flan-t5.\n",
        "\n",
        "Nous chargeons également le **Tokenizer** afin de convertir le texte en tokens et vice-versa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "DB1aJt00hiOF"
      },
      "outputs": [],
      "source": [
        "model_name='google/flan-t5-base'\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgncLTmVhiOF"
      },
      "source": [
        "**Exercice** : en vous aidant de la documentation https://huggingface.co/docs/transformers/llm_tutorial :\n",
        "- Générer et afficher les tokens (ids) de la phrase (encodage)\n",
        "- Décoder la liste de tokens (ids) et afficher la phrase (décodage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "NzG4i1MshiOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d03f92d-7e22-4f29-a8d7-db6f02fabbe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokens encodés : tensor([ 7227,     3, 16162,    18,    17,    76,   140,  5794,   244,   110,\n",
            "          301, 11160,     7,     3,    58,     1], device='cuda:0')\n",
            "\n",
            "Décodage des tokens : ['Que', '', 'peux', '-', 't', 'u', 'me', 'dire', 'sur', 'les', 'L', 'LM', 's', '', '?', '']\n",
            "\n",
            " Quepeux-tumediresurlesLLMs?\n"
          ]
        }
      ],
      "source": [
        "sentence = \"Que peux-tu me dire sur les LLMs ?\"\n",
        "\n",
        "# Encoder la phrase en tokens : suite d'ID ; 1 ID = 1 token\n",
        "\n",
        "inputs = tokenizer(sentence, return_tensors=\"pt\").to(device)\n",
        "\n",
        "print(\"\\nTokens encodés :\", inputs[\"input_ids\"][0])\n",
        "\n",
        "# METTRE ICI LE CODE POUR DECOER UNE SEQUENCE D'ID EN PHRASE ET L'AFFICHER\n",
        "\n",
        "res = tokenizer.batch_decode(inputs[\"input_ids\"][0], skip_special_tokens=True)\n",
        "print(\"\\nDécodage des tokens :\", res)\n",
        "\n",
        "st = \"\"\n",
        "for token in res:\n",
        "  st += token\n",
        "\n",
        "print(\"\\n\", st)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJTVLINahiOH"
      },
      "source": [
        "## Interrogation du LLM\n",
        "\n",
        "A présent, utilisons notre LLM pour générer du texte.\n",
        "\n",
        "Notez la syntaxe `User: question? Assistant: \"`. Nous utilisons cette syntaxe car le LLM est un modèle qui génère la suite de la phrase et cette syntaxe lui permet de comprendre ce qu'on attend de lui. Ceci à la différence des modèles d'instruction qui génèrent une réponse pour une instruction donnée."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "mjcOrnwKhiOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58b4e874-9ec1-4693-fbf8-6b820731a81b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paris\n"
          ]
        }
      ],
      "source": [
        "sentence = \"User: quelle est la capitale de la france ?Assistant: \"\n",
        "\n",
        "inputs = tokenizer(sentence, return_tensors='pt') # return les tenseurs au format pytorch\n",
        "inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
        "model = model.to(\"cuda\")\n",
        "\n",
        "output_ids = model.generate(\n",
        "    inputs[\"input_ids\"],\n",
        "    max_new_tokens=50\n",
        ")\n",
        "\n",
        "output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOURA60FhiOI"
      },
      "source": [
        "C'est assez basique pour l'instant mais ne vous inquiétez pas, ce n'est que le premier TP ;)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8rGKShUhiOI"
      },
      "source": [
        "## Résumé de dialogues\n",
        "\n",
        "Dans cette partie, nous allons utiliser le LLM pour résumer des dialogues.\n",
        "\n",
        "Tout d'abord, téléchargeons le dataset [DialogSum](https://huggingface.co/datasets/knkarthick/dialogsum) depuis Huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "cvD_-T7PhiOI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "c2ea3101916742afa2222566f07da140",
            "db1bd61675a64511abfecdb2868d9219",
            "7ba4289f736349f6a2115af9a30b9b75",
            "313b4568042e4693ba0e5cb1e841a926",
            "17b1e70469854002a00ed4cde7d44f38",
            "76d114096a954591abc6f1a16def682a",
            "cb86d74a03ec4c63b7517311c3f0017f",
            "b8e7ad8824ad48b69207651a93677bfd",
            "735d10906aca46c6bfdcbd9645e88d15",
            "e752c591317e41e8b5b0162e3865fe56",
            "0c923d7cfc62421b95c4026aab5dd79a",
            "f2fd11ef943c4ed3b543351e663aa472",
            "8bf1192826c04d0fab798da40ebbdf81",
            "44eb4e22323e4596ac323d970f14eff1",
            "c4b6cc0adcaa465ca3eab8392cd5788a",
            "8864b718a6d04c5e85a02405feb6dea7",
            "00676fb5626244f4990711a1c2bd05f2",
            "99658a5b5f53434b9395bdbb579c6314",
            "7c6ccb1b93f641e9ba31375c8a36ad77",
            "71f72cf69ff94281b258171df78e9ac6",
            "db7d77c8c7464b8c9bcc3683c35d493b",
            "4db43aa0db9b494ea4e5ca8434e31fef",
            "fc3dc938d7b04d84a344207a65efc8b4",
            "31aeed1310a54bedb92b684f3f77f8ee",
            "01ad49dd40dd421893d710ab75f77299",
            "706a02cdeeb044c68b99b38522dc5d1e",
            "177ae7e448464f66aba508af95f56252",
            "ffa974a72c854b2a8e23465a6f14b532",
            "0a23c6ddb60246768792474cd559ead5",
            "13a477630bad4d9c90b4907314f41d40",
            "53ab171234034eb4ab7962cc247444f4",
            "4839d2fa6bf74149b88bf7fafe9c39d6",
            "6794989d65ad4231ab8fdf1ba3dd8e60",
            "d6e6e119b73e48e8957aeaca6da429f1",
            "83bdbe45f10a406584392eefe7d8cc9d",
            "4c5f15db0e404ec98e65fcb9aa5dbd46",
            "c5f1672ef6804561b1d7f0c4d1aef7f6",
            "b27317846f5f44718efd42a1a2bd7f1d",
            "551fb7bb71bf4750a70c3dff74e761f1",
            "1789f4195feb4491b93ee79cc6528408",
            "b564b25ef1594da7b18c9a07ae15ef31",
            "6cb8ee2d6d774c8ab50600fceb0d9291",
            "10b8da1665b04156bb663a495286d27e",
            "e7bcb330d4f44d20830b30acd97a70a6",
            "9ddb17ed47c14f72b5a97e00c3e37282",
            "e9d30341c03c48f88608ef886f88c2e9",
            "9f7ca3ee96864fcb992da367eadbe3b9",
            "67c875d182154387b661deb0504a1f20",
            "e5df4165d8db4cbfa3b8017837461907",
            "77a626e368d149db9fd82e6457d7e8c4",
            "183a1576272d415da0e1bbc5888a5570",
            "606b236fff7b4ba9a221bcb2f1de3b5d",
            "8088f42f371848a2ab16ccf510a1bec8",
            "99a0d7a2af63412ab70320854645c66c",
            "4c7273ba016b42678269a6bb94f32c35",
            "f521ab4b77894a94948948c4d8c74c83",
            "77c4b870769e4d728981f736b9abdb7f",
            "e843f651dc7e43068284376c0f89343f",
            "0da12793aed94da08e65d7207d4deb86",
            "862c0c081d1847f281f2d0703a94c3e9",
            "35bd6f0d27c34f19b7fedab103b276ff",
            "c0628784286c40e9ab4628829b51e0e1",
            "ccc286ec73ae4dbcba81bab929d757c2",
            "9533637158b944498cde4be0e8a745f1",
            "e8b90764f524422780e6e3b23d1e85f6",
            "efff0b23d0dd47f38fc7840bc6d7d0f1",
            "3f75543a86984208a36b5c1ae6c31b55",
            "38886d7f5bc740e39c3310c78c338f4c",
            "b49a954c87164976b908c22d49075c3e",
            "16b65ae0a23749ec9d5d84dc34262f69",
            "f51828e1ba714d0aa0fd60b8c9d4fb9b",
            "3198097bc1e442d39b5783eeddf39825",
            "40066b747288413a930ee0d61e09840c",
            "92d770b3950d41ccabbb3965998b46ab",
            "70e07699437a4057879f7839f5d00ed5",
            "ff3c943e57d34a4895955aadfa13c843",
            "6b40da90b84a49f1b7703da428b0287a"
          ]
        },
        "outputId": "42ef5c04-624a-4442-fed4-889c770c3493"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2ea3101916742afa2222566f07da140"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train.csv:   0%|          | 0.00/11.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2fd11ef943c4ed3b543351e663aa472"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation.csv: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc3dc938d7b04d84a344207a65efc8b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test.csv: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6e6e119b73e48e8957aeaca6da429f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/12460 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ddb17ed47c14f72b5a97e00c3e37282"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f521ab4b77894a94948948c4d8c74c83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f75543a86984208a36b5c1ae6c31b55"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
        "dataset = load_dataset(huggingface_dataset_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0lu_YLOhiOI"
      },
      "source": [
        "Affichons 2 exemples de dialogues, les exemples numéro 40 et 200."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "-9R1vDm3hiOI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "37ff658a-0769-41c5-a433-92df35cd3e37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "Example  1\n",
            "---------------------------------------------------------------------------------------------------\n",
            "DIALOGUE D ENTREE:\n",
            "#Person1#: What time is it, Tom?\n",
            "#Person2#: Just a minute. It's ten to nine by my watch.\n",
            "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
            "#Person2#: What's the hurry?\n",
            "#Person1#: I must catch the nine-thirty train.\n",
            "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "RESUME HUMAIN:\n",
            "#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Example  2\n",
            "---------------------------------------------------------------------------------------------------\n",
            "DIALOGUE D ENTREE:\n",
            "#Person1#: Have you considered upgrading your system?\n",
            "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
            "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
            "#Person2#: That would be a definite bonus.\n",
            "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
            "#Person2#: How can we do that?\n",
            "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
            "#Person2#: No.\n",
            "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
            "#Person2#: That sounds great. Thanks.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "RESUME HUMAIN:\n",
            "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example_indices = [40, 200]\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "\n",
        "for i, index in enumerate(example_indices):\n",
        "    print(dash_line)\n",
        "    print('Example ', i + 1)\n",
        "    print(dash_line)\n",
        "    print('DIALOGUE D ENTREE:')\n",
        "    print(dataset['test'][index]['dialogue'])\n",
        "    print(dash_line)\n",
        "    print('RESUME HUMAIN:')\n",
        "    print(dataset['test'][index]['summary'])\n",
        "    print(dash_line)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUPTXFaMhiOI"
      },
      "source": [
        "Tentons une première approche pour résumer les dialogues 40 et 200."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "kfAa3kYYhiOI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd65297b-de2e-411f-e2da-a396fa4759b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "Example  1\n",
            "---------------------------------------------------------------------------------------------------\n",
            "DIALOGUE D ENTREE::\n",
            "#Person1#: What time is it, Tom?\n",
            "#Person2#: Just a minute. It's ten to nine by my watch.\n",
            "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
            "#Person2#: What's the hurry?\n",
            "#Person1#: I must catch the nine-thirty train.\n",
            "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "RESUME HUMAIN:\n",
            "#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "RESUME PAR LLM SANS PROMPT ENGINEERING:\n",
            "Person1: It's ten to nine.\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Example  2\n",
            "---------------------------------------------------------------------------------------------------\n",
            "DIALOGUE D ENTREE::\n",
            "#Person1#: Have you considered upgrading your system?\n",
            "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
            "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
            "#Person2#: That would be a definite bonus.\n",
            "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
            "#Person2#: How can we do that?\n",
            "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
            "#Person2#: No.\n",
            "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
            "#Person2#: That sounds great. Thanks.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "RESUME HUMAIN:\n",
            "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "RESUME PAR LLM SANS PROMPT ENGINEERING:\n",
            "#Person1#: I'm thinking of upgrading my computer.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i, index in enumerate(example_indices):\n",
        "    dialogue = dataset['test'][index]['dialogue']\n",
        "    summary = dataset['test'][index]['summary']\n",
        "\n",
        "    inputs = tokenizer(dialogue, return_tensors='pt') # retourner les tenseurs\n",
        "    inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
        "    output = tokenizer.decode(\n",
        "        model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_new_tokens=50, # max 50 tokens générés\n",
        "        )[0],\n",
        "        skip_special_tokens=True # on ne génère pas les tokens spéciaux <, >, ...\n",
        "    )\n",
        "\n",
        "    print(dash_line)\n",
        "    print('Example ', i + 1)\n",
        "    print(dash_line)\n",
        "    print(f'DIALOGUE D ENTREE::\\n{dialogue}')\n",
        "    print(dash_line)\n",
        "    print(f'RESUME HUMAIN:\\n{summary}')\n",
        "    print(dash_line)\n",
        "    print(f'RESUME PAR LLM SANS PROMPT ENGINEERING:\\n{output}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xnv-30WhiOI"
      },
      "source": [
        "**Exercice** : selon vous est-ce que le résumé est bon ? Pourquoi ?\n",
        "\n",
        "Le résumé n'est pas bon car das les deux cas, le LLM retourne seulement une information précise qu'il a compris du texte, mais qui ne résume pas du tout le texte."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9krxeKt3hiOJ"
      },
      "source": [
        "## Résumé avec un prompt Instruction\n",
        "\n",
        "Dans l'exemple ci-dessous, ajoutons une instruction indiquant au LLM ce qu'il doit faire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs7DzU6ThiOJ"
      },
      "source": [
        "### 1. Zero shot inference\n",
        "\n",
        "Pour amener le modèle à accomplir une tâche, comme résumer un dialogue, vous pouvez transformer ce dialogue en une consigne spécifique. Cela est connu sous le nom d'inférence zéro-shot.\n",
        "\n",
        "En encadrant le dialogue dans une consigne descriptive, vous pourrez observer les modifications apportées au texte généré."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "hfT5Z0lAhiOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a845a317-8607-4a7b-9673-2c0e5020d159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "Example  1\n",
            "---------------------------------------------------------------------------------------------------\n",
            "DIALOGUE D ENTREE:\n",
            "\n",
            "Summarize the following conversation between two persons to extract the key points of the conversation.\n",
            "\n",
            "#Person1#: What time is it, Tom?\n",
            "#Person2#: Just a minute. It's ten to nine by my watch.\n",
            "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
            "#Person2#: What's the hurry?\n",
            "#Person1#: I must catch the nine-thirty train.\n",
            "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
            "\n",
            "Summary:\n",
            "    \n",
            "---------------------------------------------------------------------------------------------------\n",
            "RESME HUMAIN:\n",
            "#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
            "---------------------------------------------------------------------------------------------------\n",
            ">>>RESME AVEC ZERO SHOT INFERENCE:\n",
            "The train is about to leave, but Tom has to catch it.\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Example  2\n",
            "---------------------------------------------------------------------------------------------------\n",
            "DIALOGUE D ENTREE:\n",
            "\n",
            "Summarize the following conversation between two persons to extract the key points of the conversation.\n",
            "\n",
            "#Person1#: Have you considered upgrading your system?\n",
            "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
            "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
            "#Person2#: That would be a definite bonus.\n",
            "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
            "#Person2#: How can we do that?\n",
            "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
            "#Person2#: No.\n",
            "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
            "#Person2#: That sounds great. Thanks.\n",
            "\n",
            "Summary:\n",
            "    \n",
            "---------------------------------------------------------------------------------------------------\n",
            "RESME HUMAIN:\n",
            "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
            "---------------------------------------------------------------------------------------------------\n",
            ">>>RESME AVEC ZERO SHOT INFERENCE:\n",
            "#Person1: Have you considered upgrading your system? #Person2: Yes, but I'm not sure what exactly I would need. #Person1: You could add a painting program to your software. #Person\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i, index in enumerate(example_indices):\n",
        "    dialogue = dataset['test'][index]['dialogue']\n",
        "    summary = dataset['test'][index]['summary']\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Summarize the following conversation between two persons to extract the key points of the conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary:\n",
        "    \"\"\"\n",
        "\n",
        "    # Input constructed prompt instead of the dialogue.\n",
        "    inputs = tokenizer(prompt, return_tensors='pt')\n",
        "    inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
        "    output = tokenizer.decode(\n",
        "        model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_new_tokens=50,\n",
        "        )[0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    print(dash_line)\n",
        "    print('Example ', i + 1)\n",
        "    print(dash_line)\n",
        "    print(f'DIALOGUE D ENTREE:\\n{prompt}')\n",
        "    print(dash_line)\n",
        "    print(f'RESME HUMAIN:\\n{summary}')\n",
        "    print(dash_line)\n",
        "    print(f'>>>RESME AVEC ZERO SHOT INFERENCE:\\n{output}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWSQZJsthiOJ"
      },
      "source": [
        "C'est déjà mieux ! Mais on peut encore faire mieux. Essayons de rajouter un exemple de résumé."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS6Y7g8jhiOJ"
      },
      "source": [
        "### 2. One Shot Inference\n",
        "\n",
        "L'inférence one-shot et few-shot consiste à fournir au modèle de langage un ou plusieurs exemples complets de paires consigne-réponse correspondant à votre tâche avant de lui soumettre la consigne réelle que vous souhaitez qu'il accomplisse. Cela s'appelle \"l'apprentissage en contexte\" (_in context learning_), et cela permet au modèle de comprendre votre tâche spécifique. Pour en savoir plus, vous pouvez consulter [cet article](https://huggingface.co/blog/few-shot-learning-gpt-neo-and-inference-api)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G93TtDzphiOJ"
      },
      "source": [
        "Définissons une fonction qui permet de générer un prompt avec 1 exemple de dialogue et son résumé."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ax1szn3xhiOJ"
      },
      "outputs": [],
      "source": [
        "def make_prompt(example_indices_full, example_index_to_summarize):\n",
        "    prompt = ''\n",
        "    for index in example_indices_full:\n",
        "        dialogue = dataset['test'][index]['dialogue']\n",
        "        summary = dataset['test'][index]['summary']\n",
        "\n",
        "        # The stop sequence '{summary}\\n\\n\\n' is important for FLAN-T5. Other models may have their own preferred stop sequence.\n",
        "        prompt += f\"\"\"\n",
        "Dialogue:\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary:\n",
        "{summary}\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    dialogue = dataset['test'][example_index_to_summarize]['dialogue']\n",
        "\n",
        "    prompt += f\"\"\"\n",
        "Dialogue:\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkLDFcadhiOJ"
      },
      "source": [
        "Construsons le prompt et affichons le."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "dzU_E_mxhiOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b013503-76db-4e79-ea16-a51d3fd50288"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dialogue:\n",
            "\n",
            "#Person1#: What time is it, Tom?\n",
            "#Person2#: Just a minute. It's ten to nine by my watch.\n",
            "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
            "#Person2#: What's the hurry?\n",
            "#Person1#: I must catch the nine-thirty train.\n",
            "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
            "\n",
            "Summary:\n",
            "#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
            "\n",
            "\n",
            "\n",
            "Dialogue:\n",
            "\n",
            "#Person1#: Have you considered upgrading your system?\n",
            "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
            "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
            "#Person2#: That would be a definite bonus.\n",
            "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
            "#Person2#: How can we do that?\n",
            "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
            "#Person2#: No.\n",
            "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
            "#Person2#: That sounds great. Thanks.\n",
            "\n",
            "Summary:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example_indices_full = [40]\n",
        "example_index_to_summarize = 200\n",
        "\n",
        "one_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n",
        "# one_shot_prompt is a string\n",
        "print(one_shot_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EKiIV_EhiOK"
      },
      "source": [
        "Lançons l'inférence sur un dialogue, qui doit bien entendu être différent de celui utilisé pour réaliser l'exemple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "YSo-ErTkhiOK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb438741-f472-4b68-bdb4-4c44c3de8d10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "RESME HUMAIN:\n",
            "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            ">>>RESME LLM AVEC ONE SHOT INFERENCE:\n",
            "#Person1#: You could add a painting program to your software. #Person2#: That would be a bonus. #Person1#: You might also want to upgrade your hardware because it is pretty outdated now\n"
          ]
        }
      ],
      "source": [
        "summary = dataset['test'][example_index_to_summarize]['summary']\n",
        "\n",
        "inputs = tokenizer(one_shot_prompt, return_tensors='pt')\n",
        "inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
        "output = tokenizer.decode(\n",
        "    model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=50,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(dash_line)\n",
        "print(f'RESME HUMAIN:\\n{summary}\\n')\n",
        "print(dash_line)\n",
        "print(f'>>>RESME LLM AVEC ONE SHOT INFERENCE:\\n{output}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vomAsqGchiOK"
      },
      "source": [
        "Voilà qui est encore mieux !!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGoW9b2qhiOK"
      },
      "source": [
        "### 3. Few shot inference\n",
        "\n",
        "Essayons à présent de fournir 3 exemples de paires (dialogue, résumé). C'est ce que l'on appelle le **few shot inference**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "IxgxmHYdhiOK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2964fb1-06f8-4e3a-e3a8-ad5e4d36d56b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dialogue:\n",
            "\n",
            "#Person1#: What's wrong with you, Mr. Polly?\n",
            "#Person2#: What's wrong? I want a break from this horrible job.\n",
            "#Person1#: Then, buy a bottle of soft drink.\n",
            "#Person2#: Would you like to buy a bottle for me in the shop?\n",
            "#Person1#: It's a problem, because my boss is in that shop now.\n",
            "#Person2#: Ok, I will go there myself.\n",
            "#Person1#: Sorry, Mr. Polly.\n",
            "#Person2#: It doesn't matter. Oh, God, I have only four dollars in my wallet. Is that possible for me to buy one?\n",
            "#Person1#: Have a try.\n",
            "\n",
            "Summary:\n",
            "Mr. Polly wants to get a break from work and he asks #Person1# to buy a drink for him, but #Person1# refuses.\n",
            "\n",
            "\n",
            "\n",
            "Dialogue:\n",
            "\n",
            "#Person1#: Hello, this is Francis.\n",
            "#Person2#: Hi, this is Monica. I was wondering when we can work on this financial report.\n",
            "#Person1#: Today, I am busy all day long.\n",
            "#Person2#: Shall I see you on Friday morning?\n",
            "#Person1#: That's not good for me at all. It'll have to be another time.\n",
            "#Person2#: We must find some time to read report.\n",
            "#Person1#: I know. I am available from 1 PM to 4 PM on Friday afternoon.\n",
            "#Person2#: That's all right. Then see you on Friday afternoon.\n",
            "#Person1#: See you.\n",
            "\n",
            "Summary:\n",
            "Francis and Monica are discussing when to work on the financial report.\n",
            "\n",
            "\n",
            "\n",
            "Dialogue:\n",
            "\n",
            "#Person1#: Is this the workshop to prepare for an interview?\n",
            "#Person2#: This is the interview class. Welcome to our class.\n",
            "#Person1#: I am really excited to be taking this workshop so that I can get ready for my interview next week.\n",
            "#Person2#: We are all learning things that will help us in our interview. What do you think are some important considerations going into your interview?\n",
            "#Person1#: I think that we should dress neatly and appropriately.\n",
            "#Person2#: Yes. Second, as you can imagine, attitude and friendliness go a long way.\n",
            "#Person1#: Yes, and I always feel much better when I am friendly.\n",
            "#Person2#: Believe it or not, the interviewers are as interested in your questions as they are in your answers.\n",
            "#Person1#: Any more hints as to what I should do in an interview?\n",
            "#Person2#: Always be honest with your answers. The interviewers really do want to know if you will be a good fit for them.\n",
            "\n",
            "Summary:\n",
            "#Person1# takes an interview workshop. #Person2# offer #Person1# some useful tips on getting ready for an interview.\n",
            "\n",
            "\n",
            "\n",
            "Dialogue:\n",
            "\n",
            "#Person1#: How large is the plant?\n",
            "#Person2#: It covers an area of 75, 000 square meters.\n",
            "#Person1#: It's much larger than I expected. When was the plant set up?\n",
            "#Person2#: In the early 70s. We'll soon be celebrating the 30th anniversary.\n",
            "#Person1#: Congratulations!\n",
            "#Person2#: Thank you.\n",
            "#Person1#: How many employees do you have in this plant?\n",
            "#Person2#: 500. We're running on three shifts.\n",
            "#Person1#: Does the plant work with everything from the raw material to the finished product?\n",
            "#Person2#: Our associates specializing in these fields make some access - ries. Well, here we're at the production shop. Shall we start with the assembly line?\n",
            "#Person1#: That's fine.\n",
            "\n",
            "Summary:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example_indices_full = [91, 93, 97] # exemples à fournir\n",
        "example_index_to_summarize = 210 # dialogue à résumer\n",
        "\n",
        "few_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n",
        "\n",
        "print(few_shot_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "ppjQcSSNhiOK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59df21a3-5dc7-4932-f290-ac304d761b6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "RESUME HUMAIN:\n",
            "#Person1# is visiting a large plant and #Person2# introduces its basic information.\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            ">>>RESUME LLM AVEC FEW SHOT INFERENCE:\n",
            "The plant is a large plant with a capacity of 500 employees. It was set up in the early 70s. It's 30 years old.\n"
          ]
        }
      ],
      "source": [
        "summary = dataset['test'][example_index_to_summarize]['summary']\n",
        "\n",
        "inputs = tokenizer(few_shot_prompt, return_tensors='pt')\n",
        "inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
        "output = tokenizer.decode(\n",
        "    model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=50,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(dash_line)\n",
        "print(f'RESUME HUMAIN:\\n{summary}\\n')\n",
        "print(dash_line)\n",
        "print(f'>>>RESUME LLM AVEC FEW SHOT INFERENCE:\\n{output}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7D-m-RmhiOK"
      },
      "source": [
        "**Exercice** : modifier les exemples fournis en entrée et indiquer ce que vous contacter en commentaire dans une section markdown.\n",
        "\n",
        "Le fait de changer les dialogues d'exemple change aussi la réponse que fait le LLM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jbvOU6ChiOK"
      },
      "source": [
        "## Influence des paramètres du LLM\n",
        "\n",
        "Nous allons maintenant faire varier plusieurs paramètres du LLM :\n",
        "- température\n",
        "- top_k\n",
        "- top_p\n",
        "- sampling\n",
        "\n",
        "Pour cela aidez-vous de la documentation :\n",
        "- https://huggingface.co/docs/transformers/generation_strategies\n",
        "- https://huggingface.co/docs/transformers/main_classes/text_generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9xRhDa_hiOK"
      },
      "source": [
        "**Exercice** : créer une fonction qui prend les 4 paramètres ci-dessous et le paramètres _few_shot_prompt_ défini précédemment et qui retourne le résultat de la génération."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "keGA-NaxhiOO"
      },
      "outputs": [],
      "source": [
        "def generate_summary(temperature, top_k, top_p, sampling, prompt):\n",
        "    inputs = tokenizer(prompt, return_tensors='pt')\n",
        "    inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
        "    output = tokenizer.decode(\n",
        "        model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_new_tokens=50,\n",
        "            do_sample=sampling,\n",
        "            temperature=temperature,\n",
        "            top_k=top_k,\n",
        "            top_p=top_p,\n",
        "        )[0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test de generate_summary\n",
        "dialogue = dataset['test'][201]['dialogue']\n",
        "human_summary = dataset['test'][201]['summary']\n",
        "\n",
        "print(\"Dialogue:\\n\")\n",
        "print(dialogue)\n",
        "print(\"\\nHuman Summary:\")\n",
        "print(human_summary)\n",
        "print(\"\\nGenerated Summary:\")\n",
        "output = generate_summary(0.7, 50, 0.9, True, few_shot_prompt)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDx3Wy6V0lCw",
        "outputId": "0c5478fc-7fbf-4bf7-c1fb-f9030afc0e0b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialogue:\n",
            "\n",
            "#Person1#: Where to, miss?\n",
            "#Person2#: Hi! Crenshaw and Hawthorne, at the Holiday Inn that is on that corner.\n",
            "#Person1#: Sure thing. So, where are you flying in from?\n",
            "#Person2#: From China.\n",
            "#Person1#: Really? You don't look very Chinese to me, if you don't mind me saying so.\n",
            "#Person2#: It's fine. I am actually from Mexico. I was in China on a business trip, visiting some local companies that manufacture bathroom products.\n",
            "#Person1#: Wow sounds interesting! Excuse me if I am being a bit nosy but, how old are you?\n",
            "#Person2#: Don't you know it's rude to ask a lady her age?\n",
            "#Person1#: Don't get me wrong! It's just that you seem so young and already doing business overseas!\n",
            "#Person2#: Well thank you! In that case, I am 26 years old, and what about yourself?\n",
            "#Person1#: I am 40 years old and was born and raised here in the good old U. S of A, although I have some Colombian heritage.\n",
            "#Person2#: Really? That's great! Do you speak some Spanish?\n",
            "#Person1#: Uh. . . yeah. . of course!\n",
            "#Person2#: Que bien! Sentences poems habeas en espanol!\n",
            "\n",
            "Human Summary:\n",
            "#Person1# is driving #Person2# to an inn. They talk about their careers, ages, and where they was born.\n",
            "\n",
            "Generated Summary:\n",
            "A man from Mexico is flying to China.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemples de valeurs de paramètres à l'inférence à tester (température, top_k, top_p, sampling)\n",
        "param_sets = [\n",
        "    (0.7, 50, 0.9, True),\n",
        "    (1.0, 50, 0.9, True),\n",
        "    (0.5, 50, 0.9, True),\n",
        "    (0.7, 20, 0.9, True),\n",
        "    (0.7, 50, 0.5, True),\n",
        "    (0.7, 50, 0.9, False),\n",
        "]\n",
        "\n",
        "# Dialogues à tester\n",
        "dialogue_indices = [11, 45, 199]\n",
        "\n",
        "# Dialogues d'exemples résumés pour le few-shots\n",
        "few_shot_examples = [84, 85, 86]\n",
        "\n",
        "for dialogue_idx in dialogue_indices:\n",
        "    dialogue_text = dataset['test'][dialogue_idx]['dialogue']\n",
        "    human_summary = dataset['test'][dialogue_idx]['summary']\n",
        "\n",
        "    print(f\"\\nDialogue {dialogue_idx}:\")\n",
        "    print(f\"Human Summary: {human_summary}\")\n",
        "\n",
        "    for i, params in enumerate(param_sets):\n",
        "        print(f\"\\n--- Parameter Set {i+1}: temp={params[0]}, top_k={params[1]}, top_p={params[2]}, sampling={params[3]} ---\")\n",
        "\n",
        "        # Création du prompt\n",
        "        prompt = make_prompt(few_shot_examples, dialogue_idx)\n",
        "\n",
        "        # Génération de la réponse\n",
        "        output = generate_summary(*params, prompt)\n",
        "\n",
        "        print(f\"Generated Summary: {output}\")\n",
        "\n",
        "    print(dash_line, \"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODNfVenS2NLD",
        "outputId": "49a76e33-7b3a-4a10-e887-a76c8462d01e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dialogue 11:\n",
            "Human Summary: #Person1# has a dance with Brian at Brian's birthday party. Brian thinks #Person1# looks great and is popular.\n",
            "\n",
            "--- Parameter Set 1: temp=0.7, top_k=50, top_p=0.9, sampling=True ---\n",
            "Generated Summary: #Person1 wants Brian to have a dance with him.\n",
            "\n",
            "--- Parameter Set 2: temp=1.0, top_k=50, top_p=0.9, sampling=True ---\n",
            "Generated Summary: Brian's birthday is on 30th August. Brian invites the party host, Lady Sally, who will perform a dance with Brian.\n",
            "\n",
            "--- Parameter Set 3: temp=0.5, top_k=50, top_p=0.9, sampling=True ---\n",
            "Generated Summary: #Person1# is celebrating his birthday. #Person2# is going to have a dance with Brian.\n",
            "\n",
            "--- Parameter Set 4: temp=0.7, top_k=20, top_p=0.9, sampling=True ---\n",
            "Generated Summary: #Person1# wishes Brian a happy birthday. #Person2# invites Brian to have a dance with him.\n",
            "\n",
            "--- Parameter Set 5: temp=0.7, top_k=50, top_p=0.5, sampling=True ---\n",
            "Generated Summary: #Person1#: Happy birthday, Brian. #Person2#: It's a great party. #Person1#: It's a great party. #Person2#: You look very pretty today\n",
            "\n",
            "--- Parameter Set 6: temp=0.7, top_k=50, top_p=0.9, sampling=False ---\n",
            "Generated Summary: #Person1#: Happy birthday, Brian. #Person2#: I'm so happy you remember. #Person1#: This is really wonderful party. #Person2#: You look very pretty today. #\n",
            "--------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "\n",
            "Dialogue 45:\n",
            "Human Summary: #Person1# tells #Person2# that Ruojia is married and will have a party tonight. #Person2#'s surprised to know that. They will bring their gifts to bless her.\n",
            "\n",
            "--- Parameter Set 1: temp=0.7, top_k=50, top_p=0.9, sampling=True ---\n",
            "Generated Summary: Ruojia's got married.\n",
            "\n",
            "--- Parameter Set 2: temp=1.0, top_k=50, top_p=0.9, sampling=True ---\n",
            "Generated Summary: Ruojia's got married yesterday. She is very happy for her. She should buy some wineglasses and a card to wish her happy marriage.\n",
            "\n",
            "--- Parameter Set 3: temp=0.5, top_k=50, top_p=0.9, sampling=True ---\n",
            "Generated Summary: Ruojia has got married.\n",
            "\n",
            "--- Parameter Set 4: temp=0.7, top_k=20, top_p=0.9, sampling=True ---\n",
            "Generated Summary: Ruojia's got married. She will bring a pair of wineglasses and a card to the party.\n",
            "\n",
            "--- Parameter Set 5: temp=0.7, top_k=50, top_p=0.5, sampling=True ---\n",
            "Generated Summary: Ruojia got married yesterday. She sends an email about it. She will bring wineglasses and a card to her wedding.\n",
            "\n",
            "--- Parameter Set 6: temp=0.7, top_k=50, top_p=0.9, sampling=False ---\n",
            "Generated Summary: Ruojia has got married.\n",
            "--------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n",
            "\n",
            "Dialogue 199:\n",
            "Human Summary: #Person1# tells #Person2# how to upgrade #Person2#'s system for better software and hardware.\n",
            "\n",
            "--- Parameter Set 1: temp=0.7, top_k=50, top_p=0.9, sampling=True ---\n",
            "Generated Summary: #Person1#: I'd like to upgrade my software, but I'm not sure what exactly I would need. #Person1#: You could add a painting program to your software. #Person1#:\n",
            "\n",
            "--- Parameter Set 2: temp=1.0, top_k=50, top_p=0.9, sampling=True ---\n",
            "Generated Summary: #Person1 is thinking of upgrading their computer system. It would help them to make up their own flyers and banners. #Person2 says that they could also add a painting program.\n",
            "\n",
            "--- Parameter Set 3: temp=0.5, top_k=50, top_p=0.9, sampling=True ---\n",
            "Generated Summary: #Person1#: Have you considered upgrading your system? #Person2#: Yes, but I'm not sure what exactly I would need. #Person1#: You could consider adding a painting program to your software\n",
            "\n",
            "--- Parameter Set 4: temp=0.7, top_k=20, top_p=0.9, sampling=True ---\n",
            "Generated Summary: #Person2#: Have you considered upgrading your system? #Person1#: Yes, but I'm not sure what exactly I would need. #Person1#: You could consider adding a painting program to your software\n",
            "\n",
            "--- Parameter Set 5: temp=0.7, top_k=50, top_p=0.5, sampling=True ---\n",
            "Generated Summary: #Person1#: Have you considered upgrading your system? #Person2#: Yes, but I'm not sure what exactly I would need. #Person1#: You could also add a painting program to your software\n",
            "\n",
            "--- Parameter Set 6: temp=0.7, top_k=50, top_p=0.9, sampling=False ---\n",
            "Generated Summary: #Person1#: Have you considered upgrading your system? #Person2#: Yes, but I'm not sure what exactly I would need. #Person1#: You could consider adding a painting program to your software\n",
            "--------------------------------------------------------------------------------------------------- \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILm2ya1DhiOO"
      },
      "source": [
        "**Exercice** : expliquer en 1 ou 2 lignes l'influence de chacun des 4 paramètres (dans une section markdown).\n",
        "\n",
        "La température semble être le paramètre le plus important car le cas avec une température de 1 est le seul cas qui donne un résumé satisfaisant qui n'est pas une information au hasard du dialogue.\n",
        "\n",
        "Les autres paramètres ne semblent pas influencer beaucoup la réponse en comparaison."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jilxTR2rhiOO"
      },
      "source": [
        "### Mini projet : Système de Questions-Réponses avec Classement de Qualité\n",
        "\n",
        "**Objectif** : Créer un système qui utilise un LLM pour répondre à des questions sur un domaine spécifique et évaluer la qualité des réponses.\n",
        "\n",
        "**Durée estimée** : 3-4 heures\n",
        "\n",
        "**Description du projet** :\n",
        "1. **Créer un dataset de questions-réponses** : Définir 10-15 questions sur un domaine de votre choix (technologie, cinéma, histoire, etc.) avec leurs réponses de référence\n",
        "2. **Tester différentes approches de prompt** :\n",
        "    - Zero-shot\n",
        "    - One-shot\n",
        "    - Few-shot\n",
        "3. **Comparer les paramètres de génération** : Tester différentes combinaisons de température, top_k, top_p pour voir leur impact\n",
        "4. **Évaluation automatique** : Créer une fonction qui compare la réponse du LLM avec la réponse de référence (vous pouvez utiliser des métriques simples comme la longueur, les mots-clés communs, etc.)\n",
        "5. **Visualisation des résultats** : Afficher un tableau comparatif des performances selon les différentes approches\n",
        "\n",
        "**Livrables attendus** :\n",
        "- Code documenté avec des commentaires\n",
        "- Analyse des résultats en markdown (quelle approche fonctionne le mieux ?)\n",
        "- Au moins 2 visualisations (graphiques ou tableaux)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset de questions-réponses sur le thème de l'intelligence artificielle,\n",
        "# stockées sous forme d'un dictionnaire python\n",
        "qa_dataset = {\n",
        "    1: {\n",
        "        \"question\": \"Qu’est-ce qu’un réseau de neurones artificiels ?\",\n",
        "        \"answer\": \"Un modèle composé de couches de nœuds interconnectés capables d’extraire des représentations à partir de données.\"\n",
        "    },\n",
        "    2: {\n",
        "        \"question\": \"Que signifie apprentissage supervisé ?\",\n",
        "        \"answer\": \"Un mode d’apprentissage où le modèle reçoit des exemples annotés pour apprendre à prédire une sortie correcte.\"\n",
        "    },\n",
        "    3: {\n",
        "        \"question\": \"Qu’est-ce qu’un dataset d’entraînement ?\",\n",
        "        \"answer\": \"Un ensemble de données utilisé pour ajuster les paramètres d’un modèle pendant l’apprentissage.\"\n",
        "    },\n",
        "    4: {\n",
        "        \"question\": \"À quoi sert la fonction de perte ?\",\n",
        "        \"answer\": \"À mesurer l’écart entre la prédiction du modèle et la vérité terrain, afin de guider l’optimisation.\"\n",
        "    },\n",
        "    5: {\n",
        "        \"question\": \"Qu’est-ce que le surapprentissage (overfitting) ?\",\n",
        "        \"answer\": \"Un état où le modèle mémorise les données d’entraînement au lieu de généraliser à de nouveaux exemples.\"\n",
        "    },\n",
        "    6: {\n",
        "        \"question\": \"À quoi sert la validation croisée ?\",\n",
        "        \"answer\": \"À évaluer la capacité de généralisation d’un modèle en le testant sur plusieurs partitions du dataset.\"\n",
        "    },\n",
        "    7: {\n",
        "        \"question\": \"Qu’est-ce qu’un gradient ?\",\n",
        "        \"answer\": \"La direction et l’intensité de la variation de la perte par rapport aux paramètres du modèle.\"\n",
        "    },\n",
        "    8: {\n",
        "        \"question\": \"Pourquoi utilise-t-on la descente de gradient ?\",\n",
        "        \"answer\": \"Pour ajuster les paramètres du modèle dans la direction qui minimise la fonction de perte.\"\n",
        "    },\n",
        "    9: {\n",
        "        \"question\": \"Qu’est-ce qu’un modèle de langage (LLM) ?\",\n",
        "        \"answer\": \"Un modèle entraîné à prédire la suite la plus probable de mots, capable de générer ou comprendre du texte.\"\n",
        "    },\n",
        "    10: {\n",
        "        \"question\": \"Que signifie fine-tuning ?\",\n",
        "        \"answer\": \"Adapter un modèle pré-entraîné à une tâche spécifique en le réentraînant sur un dataset ciblé.\"\n",
        "    },\n",
        "    11: {\n",
        "        \"question\": \"Qu’est-ce qu’un transformeur ?\",\n",
        "        \"answer\": \"Une architecture fondée sur l’attention, conçue pour traiter des séquences en parallèle.\"\n",
        "    },\n",
        "    12: {\n",
        "        \"question\": \"À quoi sert le mécanisme d’attention ?\",\n",
        "        \"answer\": \"À pondérer l’importance relative des éléments d’une séquence lors du traitement.\"\n",
        "    },\n",
        "    13: {\n",
        "        \"question\": \"Que désigne le terme embedding ?\",\n",
        "        \"answer\": \"Une représentation vectorielle dense capturant les relations sémantiques entre éléments.\"\n",
        "    },\n",
        "    14: {\n",
        "        \"question\": \"Qu’est-ce qu’un modèle génératif ?\",\n",
        "        \"answer\": \"Un modèle capable de produire de nouvelles données cohérentes avec ce sur quoi il a été entraîné.\"\n",
        "    },\n",
        "    15: {\n",
        "        \"question\": \"Quelle est la différence entre IA faible et IA forte ?\",\n",
        "        \"answer\": \"L’IA faible exécute des tâches spécifiques, l’IA forte désigne une IA hypothétique capable de raisonner comme un humain.\"\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "LJc2MxtXAkvc"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iO4VL79uJSxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def length_difference_distance(ref_answer: str, gen_answer: str) -> float:\n",
        "    \"\"\"\n",
        "    Retourne une distance entre deux textes basée sur la différence des longueurs.\n",
        "    La distance est comptée plus grande si le second texte est plus court que le premier.\n",
        "    \"\"\"\n",
        "    ref_len = len(ref_answer)\n",
        "    gen_len = len(gen_answer)\n",
        "\n",
        "    diff = abs(ref_len - gen_len)\n",
        "\n",
        "    # Distance plus grande si le second texte est plus court\n",
        "    if gen_len < ref_len:\n",
        "        diff *= 1.5\n",
        "\n",
        "    # Normalisation\n",
        "    return 1 - (diff / ref_len)"
      ],
      "metadata": {
        "id": "tCzM1tCGBq3-"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def common_words_distance(ref_answer: str, gen_answer: str) -> float:\n",
        "    \"\"\"\n",
        "    Retourne une distance entre deux textes basée sur le nombre de mots communs.\n",
        "    \"\"\"\n",
        "    ref_words = set(ref_answer.lower().split())\n",
        "    gen_words = set(gen_answer.lower().split())\n",
        "\n",
        "    common = ref_words & gen_words\n",
        "\n",
        "     # Normalisation\n",
        "    ratio_common = len(common) / max(len(ref_words), 1)\n",
        "\n",
        "    return ratio_common"
      ],
      "metadata": {
        "id": "_y5ZsCZmGWOl"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def cosine_distance(ref_answer: str, gen_answer: str) -> float:\n",
        "    \"\"\"\n",
        "    Retourne une distance entre deux textes basée sur le calcul\n",
        "    de la similarité cosinus.\n",
        "    \"\"\"\n",
        "    vectorizer = CountVectorizer().fit([ref_answer, gen_answer])\n",
        "    vectors = vectorizer.transform([ref_answer, gen_answer])\n",
        "\n",
        "    sim = cosine_similarity(vectors[0], vectors[1])[0][0]\n",
        "\n",
        "    return sim\n"
      ],
      "metadata": {
        "id": "CwRHfoYKHhQg"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZZDOPAahiOO"
      },
      "source": [
        "## Pour aller plus loin : langchain\n",
        "\n",
        "Faire le short course https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/\n",
        "\n",
        "A partir des compétences fraîchement acquises, réaliser une chaîne de traitement qui\n",
        "- Demande à l'utilisateur de charger un document PDF ou le charger depuis une URL\n",
        "- Permet à l'utiisateur de poser des questions sur ce document\n",
        "- Mémorise les conversations pour répondre aux questions\n",
        "\n",
        "Votre application devra utiliser des templates de prompts.\n",
        "\n",
        "- Suggestion de LLM à utiliser : https://huggingface.co/Qwen/Qwen2.5-3B-Instruct."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c2ea3101916742afa2222566f07da140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db1bd61675a64511abfecdb2868d9219",
              "IPY_MODEL_7ba4289f736349f6a2115af9a30b9b75",
              "IPY_MODEL_313b4568042e4693ba0e5cb1e841a926"
            ],
            "layout": "IPY_MODEL_17b1e70469854002a00ed4cde7d44f38"
          }
        },
        "db1bd61675a64511abfecdb2868d9219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76d114096a954591abc6f1a16def682a",
            "placeholder": "​",
            "style": "IPY_MODEL_cb86d74a03ec4c63b7517311c3f0017f",
            "value": "README.md: "
          }
        },
        "7ba4289f736349f6a2115af9a30b9b75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8e7ad8824ad48b69207651a93677bfd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_735d10906aca46c6bfdcbd9645e88d15",
            "value": 1
          }
        },
        "313b4568042e4693ba0e5cb1e841a926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e752c591317e41e8b5b0162e3865fe56",
            "placeholder": "​",
            "style": "IPY_MODEL_0c923d7cfc62421b95c4026aab5dd79a",
            "value": " 4.65k/? [00:00&lt;00:00, 339kB/s]"
          }
        },
        "17b1e70469854002a00ed4cde7d44f38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76d114096a954591abc6f1a16def682a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb86d74a03ec4c63b7517311c3f0017f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8e7ad8824ad48b69207651a93677bfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "735d10906aca46c6bfdcbd9645e88d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e752c591317e41e8b5b0162e3865fe56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c923d7cfc62421b95c4026aab5dd79a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2fd11ef943c4ed3b543351e663aa472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8bf1192826c04d0fab798da40ebbdf81",
              "IPY_MODEL_44eb4e22323e4596ac323d970f14eff1",
              "IPY_MODEL_c4b6cc0adcaa465ca3eab8392cd5788a"
            ],
            "layout": "IPY_MODEL_8864b718a6d04c5e85a02405feb6dea7"
          }
        },
        "8bf1192826c04d0fab798da40ebbdf81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00676fb5626244f4990711a1c2bd05f2",
            "placeholder": "​",
            "style": "IPY_MODEL_99658a5b5f53434b9395bdbb579c6314",
            "value": "train.csv: 100%"
          }
        },
        "44eb4e22323e4596ac323d970f14eff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c6ccb1b93f641e9ba31375c8a36ad77",
            "max": 11321474,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71f72cf69ff94281b258171df78e9ac6",
            "value": 11321474
          }
        },
        "c4b6cc0adcaa465ca3eab8392cd5788a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db7d77c8c7464b8c9bcc3683c35d493b",
            "placeholder": "​",
            "style": "IPY_MODEL_4db43aa0db9b494ea4e5ca8434e31fef",
            "value": " 11.3M/11.3M [00:00&lt;00:00, 18.5MB/s]"
          }
        },
        "8864b718a6d04c5e85a02405feb6dea7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00676fb5626244f4990711a1c2bd05f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99658a5b5f53434b9395bdbb579c6314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c6ccb1b93f641e9ba31375c8a36ad77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71f72cf69ff94281b258171df78e9ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db7d77c8c7464b8c9bcc3683c35d493b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4db43aa0db9b494ea4e5ca8434e31fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc3dc938d7b04d84a344207a65efc8b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31aeed1310a54bedb92b684f3f77f8ee",
              "IPY_MODEL_01ad49dd40dd421893d710ab75f77299",
              "IPY_MODEL_706a02cdeeb044c68b99b38522dc5d1e"
            ],
            "layout": "IPY_MODEL_177ae7e448464f66aba508af95f56252"
          }
        },
        "31aeed1310a54bedb92b684f3f77f8ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffa974a72c854b2a8e23465a6f14b532",
            "placeholder": "​",
            "style": "IPY_MODEL_0a23c6ddb60246768792474cd559ead5",
            "value": "validation.csv: "
          }
        },
        "01ad49dd40dd421893d710ab75f77299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13a477630bad4d9c90b4907314f41d40",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53ab171234034eb4ab7962cc247444f4",
            "value": 1
          }
        },
        "706a02cdeeb044c68b99b38522dc5d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4839d2fa6bf74149b88bf7fafe9c39d6",
            "placeholder": "​",
            "style": "IPY_MODEL_6794989d65ad4231ab8fdf1ba3dd8e60",
            "value": " 442k/? [00:00&lt;00:00, 13.3MB/s]"
          }
        },
        "177ae7e448464f66aba508af95f56252": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffa974a72c854b2a8e23465a6f14b532": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a23c6ddb60246768792474cd559ead5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13a477630bad4d9c90b4907314f41d40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "53ab171234034eb4ab7962cc247444f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4839d2fa6bf74149b88bf7fafe9c39d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6794989d65ad4231ab8fdf1ba3dd8e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6e6e119b73e48e8957aeaca6da429f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83bdbe45f10a406584392eefe7d8cc9d",
              "IPY_MODEL_4c5f15db0e404ec98e65fcb9aa5dbd46",
              "IPY_MODEL_c5f1672ef6804561b1d7f0c4d1aef7f6"
            ],
            "layout": "IPY_MODEL_b27317846f5f44718efd42a1a2bd7f1d"
          }
        },
        "83bdbe45f10a406584392eefe7d8cc9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_551fb7bb71bf4750a70c3dff74e761f1",
            "placeholder": "​",
            "style": "IPY_MODEL_1789f4195feb4491b93ee79cc6528408",
            "value": "test.csv: "
          }
        },
        "4c5f15db0e404ec98e65fcb9aa5dbd46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b564b25ef1594da7b18c9a07ae15ef31",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6cb8ee2d6d774c8ab50600fceb0d9291",
            "value": 1
          }
        },
        "c5f1672ef6804561b1d7f0c4d1aef7f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10b8da1665b04156bb663a495286d27e",
            "placeholder": "​",
            "style": "IPY_MODEL_e7bcb330d4f44d20830b30acd97a70a6",
            "value": " 1.35M/? [00:00&lt;00:00, 65.5MB/s]"
          }
        },
        "b27317846f5f44718efd42a1a2bd7f1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "551fb7bb71bf4750a70c3dff74e761f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1789f4195feb4491b93ee79cc6528408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b564b25ef1594da7b18c9a07ae15ef31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6cb8ee2d6d774c8ab50600fceb0d9291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10b8da1665b04156bb663a495286d27e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7bcb330d4f44d20830b30acd97a70a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ddb17ed47c14f72b5a97e00c3e37282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9d30341c03c48f88608ef886f88c2e9",
              "IPY_MODEL_9f7ca3ee96864fcb992da367eadbe3b9",
              "IPY_MODEL_67c875d182154387b661deb0504a1f20"
            ],
            "layout": "IPY_MODEL_e5df4165d8db4cbfa3b8017837461907"
          }
        },
        "e9d30341c03c48f88608ef886f88c2e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77a626e368d149db9fd82e6457d7e8c4",
            "placeholder": "​",
            "style": "IPY_MODEL_183a1576272d415da0e1bbc5888a5570",
            "value": "Generating train split: 100%"
          }
        },
        "9f7ca3ee96864fcb992da367eadbe3b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_606b236fff7b4ba9a221bcb2f1de3b5d",
            "max": 12460,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8088f42f371848a2ab16ccf510a1bec8",
            "value": 12460
          }
        },
        "67c875d182154387b661deb0504a1f20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99a0d7a2af63412ab70320854645c66c",
            "placeholder": "​",
            "style": "IPY_MODEL_4c7273ba016b42678269a6bb94f32c35",
            "value": " 12460/12460 [00:00&lt;00:00, 56202.97 examples/s]"
          }
        },
        "e5df4165d8db4cbfa3b8017837461907": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77a626e368d149db9fd82e6457d7e8c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "183a1576272d415da0e1bbc5888a5570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "606b236fff7b4ba9a221bcb2f1de3b5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8088f42f371848a2ab16ccf510a1bec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99a0d7a2af63412ab70320854645c66c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c7273ba016b42678269a6bb94f32c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f521ab4b77894a94948948c4d8c74c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77c4b870769e4d728981f736b9abdb7f",
              "IPY_MODEL_e843f651dc7e43068284376c0f89343f",
              "IPY_MODEL_0da12793aed94da08e65d7207d4deb86"
            ],
            "layout": "IPY_MODEL_862c0c081d1847f281f2d0703a94c3e9"
          }
        },
        "77c4b870769e4d728981f736b9abdb7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35bd6f0d27c34f19b7fedab103b276ff",
            "placeholder": "​",
            "style": "IPY_MODEL_c0628784286c40e9ab4628829b51e0e1",
            "value": "Generating validation split: 100%"
          }
        },
        "e843f651dc7e43068284376c0f89343f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccc286ec73ae4dbcba81bab929d757c2",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9533637158b944498cde4be0e8a745f1",
            "value": 500
          }
        },
        "0da12793aed94da08e65d7207d4deb86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8b90764f524422780e6e3b23d1e85f6",
            "placeholder": "​",
            "style": "IPY_MODEL_efff0b23d0dd47f38fc7840bc6d7d0f1",
            "value": " 500/500 [00:00&lt;00:00, 12198.77 examples/s]"
          }
        },
        "862c0c081d1847f281f2d0703a94c3e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35bd6f0d27c34f19b7fedab103b276ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0628784286c40e9ab4628829b51e0e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccc286ec73ae4dbcba81bab929d757c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9533637158b944498cde4be0e8a745f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8b90764f524422780e6e3b23d1e85f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efff0b23d0dd47f38fc7840bc6d7d0f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f75543a86984208a36b5c1ae6c31b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38886d7f5bc740e39c3310c78c338f4c",
              "IPY_MODEL_b49a954c87164976b908c22d49075c3e",
              "IPY_MODEL_16b65ae0a23749ec9d5d84dc34262f69"
            ],
            "layout": "IPY_MODEL_f51828e1ba714d0aa0fd60b8c9d4fb9b"
          }
        },
        "38886d7f5bc740e39c3310c78c338f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3198097bc1e442d39b5783eeddf39825",
            "placeholder": "​",
            "style": "IPY_MODEL_40066b747288413a930ee0d61e09840c",
            "value": "Generating test split: 100%"
          }
        },
        "b49a954c87164976b908c22d49075c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92d770b3950d41ccabbb3965998b46ab",
            "max": 1500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70e07699437a4057879f7839f5d00ed5",
            "value": 1500
          }
        },
        "16b65ae0a23749ec9d5d84dc34262f69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff3c943e57d34a4895955aadfa13c843",
            "placeholder": "​",
            "style": "IPY_MODEL_6b40da90b84a49f1b7703da428b0287a",
            "value": " 1500/1500 [00:00&lt;00:00, 35314.90 examples/s]"
          }
        },
        "f51828e1ba714d0aa0fd60b8c9d4fb9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3198097bc1e442d39b5783eeddf39825": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40066b747288413a930ee0d61e09840c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92d770b3950d41ccabbb3965998b46ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70e07699437a4057879f7839f5d00ed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff3c943e57d34a4895955aadfa13c843": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b40da90b84a49f1b7703da428b0287a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}